{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IEEEAccessmMHealth.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcosma/IEEE_Access_mHealth/blob/master/IEEEAccessmMHealth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg1TmIbqdRV6",
        "colab_type": "text"
      },
      "source": [
        "              **Click on the OPEN IN COLAB icon above**\n",
        "\n",
        "**Feature Extraction and Classification using Leading Eigenvectors: Applications to Biomedical and Multi-Modal mHealth Data** \n",
        "\n",
        "by Dr Georgina Cosma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRSejqmpfLY-",
        "colab_type": "text"
      },
      "source": [
        "**********************************************************************************************************************************************\n",
        "DESCRIPTION: This is supplementary code for the paper \"Feature Extraction and Classification using Leading Eigenvectors: Applications to Biomedical and Multi-Modal mHealth Data\" submitted to IEEE Access. \n",
        "\n",
        "Programming Language: This code was written in the Python programming language. CoLab is used for wider accessibility of the code.\n",
        "\n",
        "File name: IEEEAccessmMHealth.ipynb\n",
        "\n",
        "CONTACT INFORMATION: \n",
        "Dr Georgina Cosma, Department of Computer Science, Loughborough University.\n",
        "\n",
        "E-mail: gcosmaresearch@outlook.com\n",
        "\n",
        "Website: https://gcosma.home.blog/\n",
        "\n",
        "PAPER CITATION: Please cite:\n",
        "Cosma and McGinnity, 2019. Feature Extraction and Classification using Leading Eigenvectors: Applications to Biomedical and Multi-Modal mHealth Data. IEEE Access. \n",
        "**********************************************************************************************************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WAVoe6SpMZU",
        "colab_type": "text"
      },
      "source": [
        "Learning outcomes:\n",
        "* Load Data.\n",
        "* Apply z-score data normalisation\n",
        "* Get the frequency of each class \n",
        "* Visualise the class labels\n",
        "* Apply Singular Value Decomposition and extract the leading Eigenvectors\n",
        "* Define a Sequential model for detecting human activity in multi-sensor data\n",
        "* Compile the Sequential Model\n",
        "* Train and Test a mode using k-fold cross validation.  \n",
        "\n",
        "\n",
        "**Not using Colab?** If you are not using Colab you will need to Setup a Python Environment for \n",
        "Machine Learning and Deep Learning with Anaconda. You must have Python 2 or 3 \n",
        "installed and configured. You must install SciPy (including NumPy) and the relevant\n",
        "libraries including Keras. \n",
        "\n",
        "**Using Colab:** Some difficulties may be\n",
        "experienced with mounting, but the code and explanation here will help you overcome these. \n",
        "\n",
        "I have included the datasets  in the GitHub repository and you can also download the data from: https://archive.ics.uci.edu/ml/datasets/MHEALTH+Dataset\n",
        "\n",
        "**About the mHealth multi-sensor dataset:** The mHealth (Mobile Health) dataset is a benchmark dataset for human behaviour analysis based on multi-modal body sensing. The mHealth dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing 12 physical activities: Standing still (1 min), Sitting and relaxing (1 min), Lying down (1 min), Walking (1 min), Climbing stairs (1 min), Waist bends forward (20x), Frontal elevation of arms (20x), Knees bending (crouching) (20x), Cycling (1 min), Jogging (1 min), Running (1 min), and Jump front & back (20x). Sensors on each subject's chest, right wrist and left ankle were used to measure the motion experienced by diverse body parts, namely, acceleration, rate of turn and magnetic field orientation. All sensing modalities are recorded at a sampling rate of 50 Hz, which is considered sufficient for capturing human activity. This dataset has been found to generalize to common activities of the daily living, due to the diversity of body parts involved in each activity (e.g., frontal elevation of arms vs. knees bending), the intensity of the actions (e.g., cycling vs. sitting and relaxing) and their execution speed or dynamicity (e.g., running vs. standing still). For more information see: https://archive.ics.uci.edu/ml/datasets/MHEALTH+Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Rq10MgkEOM",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Import libraries** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYbRn_jdSBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy import stats\n",
        "#Below several optimisers are imported. This tutorial is using the Adam optimiser\n",
        "#but you can easily replace Adam with another optimiser from the list. \n",
        "from keras.optimizers import SGD, Adam, Adadelta, RMSprop, Adagrad, Adamax, Nadam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34xdjC4kTVk",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Mount to Google Drive in order to access your data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqvH4wcpkbRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "#if you need to remount\n",
        "#drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "#If you want to unmount and reset then: \n",
        "#Step 1: From the menu select Runtime--->Reset all Runtimes... \n",
        "#Step 2: Runtime--->Run all or you can run each Cell at a time. There will be a message \n",
        "# \"Go to a URL in a browser\" and you must click on that and copy and paste the authorisation code \n",
        "# from the page into the authorisation code text box.\n",
        "\n",
        "#! git clone https://github.com/gcosma/DeepLearningTutorials/DataTest\n",
        "#! git clode https://github.com/gcosma/Data\n",
        "#! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2rLtp4Hu0qR",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Choose your dataset. Each mHealth dataset belings to one person. There are 10 mHealth datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stFb9r6kkNLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All datasets are available in Github. I added the datasets into a data folder where all data are kept separate from the code. \n",
        "# To load the dataset you must uncomment the dataset you want to load. One dataset contains the data of a single person. \n",
        "dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject1txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject2txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject3txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject4txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject5txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject6txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject7txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject8txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealthdata/MHEALTHDATASET/mHealth_subject9txt.csv\", delimiter=\",\")\n",
        "#dataset = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/MHEALTHDATASET/mHealth_subject10txt.csv\", delimiter=\",\")\n",
        "\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3utKVAwj4Iu",
        "colab_type": "text"
      },
      "source": [
        "**Step 4:**\n",
        "Dataset comprises of 23 inputs, and a vector of categorical target values (0-12). Each target value corresponds to one of 12 physical activities as explained in the first part of this tutorial. Class 0 is not an activity. Hence, there are 13 classes but 12 activities. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBmDJLsWk64e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input data and labels need to be separated before training the model.\n",
        "X = dataset[:,0:23]        \n",
        "labels= dataset[:,23]\n",
        "\n",
        "#Here zscore is applied to normalise the values of each column. \n",
        "# Z-scores are linearly transformed data values having a mean of zero and a standard deviation of 1. \n",
        "X=stats.zscore(X)\n",
        "\n",
        "#Convert the single vector of 13 classes to a matrix of 1s and 0s. \n",
        "#This is called one-hot-encoding. With one-hot encoding the integer encoded variable is removed and a new binary \n",
        "# variable is added for each unique integer value. For a quick explanation see: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
        "Yenc = to_categorical(labels) \n",
        "print(Yenc)\n",
        "\n",
        "#Check the size of matrix Yenc. The number of rows should be equal to the number of classes classes.\n",
        "#In this example classes start from 0 to 12. Therefore we have 13 classes. \n",
        "Yenc.shape\n",
        "#X.shape\n",
        "#print(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSA13nYxCgLd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NTleZHVMnEx",
        "colab_type": "text"
      },
      "source": [
        "**Count the frequency of each class. The datasets are considered as Limited Training Datasets making this classification task a challenging one. The reason the datasets are considered to be limited is because the cases in the null class range from 65.73\\%-78.19\\%, whereas the cases in the remaining 12 classes range from 0.67\\%-3.13\\%. Hence, the number of cases in all classes 0-12 are comparatively lower than the 0 class, and the number of training samples are limited.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT-69cb8CgpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Count the number of cases in each class. \n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "dict(zip(unique, counts))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpEc0FbnMw7q",
        "colab_type": "text"
      },
      "source": [
        "**Plot a histogram of the labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8_29P5lMDiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(labels, bins=np.arange(labels.min(), labels.max()+1))\n",
        "plt.title(\"Histogram with 'auto' bins\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnQn9dffrY7b",
        "colab_type": "text"
      },
      "source": [
        "**Below is the code for saving the normalised data into a csv file.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-oY8yz7ks_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame. For more information on DataFrames see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "#create a Pandas DataFrame for matrix X\n",
        "df = DataFrame(X)\n",
        "#Export the DataFrame to a csv file and store it in a directory. \n",
        "export_csv = df.to_csv(r'/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/ProcessedMHEALTHDATASET/D1norm.csv', header=False, index = None)\n",
        "print (export_csv)\n",
        "\n",
        "#load the normalised csv file into a matrix\n",
        "datasetnorm = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/ProcessedMHEALTHDATASET/D1norm.csv\", delimiter=\",\")\n",
        "print(datasetnorm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_LKlVkCZVy5",
        "colab_type": "text"
      },
      "source": [
        "**Step 5: Apply Dingular Value Decomposition and Dimensionality reduction.**\n",
        "A Sparse SVD method was applied. the k number of dimensions selected were 10, hence k=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqFJoBVj7lz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import csc_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "u, s, vt = svds(datasetnorm, k=10) # apply svds with k=10 dimensions\n",
        "#print(u) # this is the patient by dimension matrix, u\n",
        "u.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SZk1wRVDZbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a panda DataFrame for storing the u patient-by-dimension matrix\n",
        "dfu = DataFrame(u)\n",
        "#Export to a csv file\n",
        "export_u = dfu.to_csv(r'/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/ProcessedMHEALTHDATASET/D1normU.csv', header=False, index = None)\n",
        "\n",
        "#Load the normalised csv file into a matrix\n",
        "U=np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/data/ProcessedMHEALTHDATASET/D1normU.csv\", delimiter=\",\")\n",
        "#print(U) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSvPiJjpoah9",
        "colab_type": "text"
      },
      "source": [
        "**Step 6: Create the Sequential model**\n",
        "A Sequential model is a linear stack of layers.\n",
        "Code for the k-fold cross validation was adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "fit(X,Y) is for training the model with the given inputs X (and corresponding training labels Y). Adjust the number of epochs to avoid overtraining your network.\n",
        "\n",
        "evaluate(X,Y) is for evaluating the already trained model using the test data. Returns the accuracy values for each k-fold using the test data. **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25NjmEwUk9Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define k-fold cross validation test. In this application the number of folds is 10, hence n_splits=10.\n",
        "# 10-fold allows us to partition the data into k different training and testing datasets. \n",
        "# k-fold, when applied to large datasets, can result in slow training, but it is a suitable \n",
        "# validation approach when the datasets are limited (see step 4 for an explanation of what is meant by 'limited'). \n",
        "# k-fold results to thorough evaluations of the model.  \n",
        "# For a nice introduction to k-fold cross validation see: https://machinelearningmastery.com/k-fold-cross-validation/\n",
        "kfold = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
        "cvscores = []\n",
        "#get number of columns in training data\n",
        "n_cols = U.shape[1]\n",
        "#Split the dataset into folds of train and test data.\n",
        "for train, test in kfold.split(U, labels):\n",
        "  model = Sequential()\n",
        "  # Dense(256) is a fully-connected layer with 256 hidden units.\n",
        "  # in the first layer, you must specify the expected input data shape:\n",
        "  # here, n_cols=23-dimensional vectors. n_cols = U.shape[1] gave \n",
        "  # the number of columns in the data. \n",
        "  # For more information on the options for constructing a Sequential model see\n",
        "  # https://keras.io/getting-started/sequential-model-guide/ \n",
        "  model.add(Dense(256, activation='relu', input_shape=(n_cols,), name='input_layer'))\n",
        "  model.add(Activation('relu', name='Activation_1'))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(256, activation='relu', name='Dense_1'))\n",
        "  model.add(Activation('relu', name='Activation_2'))\n",
        "  model.add(Dropout(0.5, name='Dropout_1'))\n",
        "  model.add(Dense(256,activation='relu', name='Dense_2'))\n",
        "  #13 refers to the number of classes. SOFTMAX is used for multi-classification.\n",
        "  model.add(Dense(13, activation='softmax', name='Dense_3'))\n",
        "\n",
        "  #####################################################################################\n",
        "  #Setup the optimisers - you can try out several one at a time \n",
        "  # simply relace optimizer='adam' when you compile the model. \n",
        "  sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "  adadelt=Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "  rmsprop=RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "  adagrad=Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
        "  adamax=Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "  nadam=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "  #####################################################################################\n",
        "\n",
        "  ############### Now you can change the name of the optimiser if you wish. \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  ############# Fit the model (training)\n",
        "  model.fit(U[train], Yenc[train], epochs=20, batch_size=50, verbose=0)\n",
        "\n",
        "  ###################### Test the model using the test data\n",
        "  score = model.evaluate(U[test], Yenc[test], batch_size=50, verbose=0)\n",
        "  print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "  #Displays the accuracy of each fold when applied to the test data.\n",
        "  cvscores.append(score[1] * 100)\n",
        "  #Indentation is important here. Show the mean accuracy and standard deviation over all k-folds\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qj6zFGLlENM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the structure of the Sequential model\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jOK1cJbxBlU",
        "colab_type": "text"
      },
      "source": [
        "**Extra code. How to install the GraphViz Library  http://www.graphviz.org/\n",
        "The image is stored in your drive.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPlJouVfpcIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pydot\n",
        "from keras.utils.vis_utils import plot_model\n",
        "#Prints the model to a file in the directory\n",
        "plot_model(model, to_file='/content/drive/My Drive/Colab Notebooks/CosmaIEEEAccessPapermHealth/model_plot3.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtq7zFjQSEem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install the dataframe panda\n",
        "!pip install dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bol9-UCgxq2O",
        "colab_type": "text"
      },
      "source": [
        "**Extra code. How to decode a one-hot-encoded matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QJL-A6_kVmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decode from one-hot-encoded matrix\n",
        "res= [np.where(r==1)[0][0] for r in Yenc]\n",
        "print(res)\n",
        "max(res)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}